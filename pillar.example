cluster:
  # Cluster name
  name: hacluster

  # Node which will create the cluster.
  # To create multiple clusters, set different
  # pillar data with different nodes as
  # firstnode. Each firstnode will create
  # a separate cluster
  init: minion-1

  # optional: nodes that should be removed
  # from the cluster.
  # remove: []

  # optional: Configure the watchdog device. module and device are mandatory
  # watchdog:
  #   module: softdog
  #   device: /dev/watchdog

  # optional: Network interface to use for cluster communication
  # interface: eth0

  # optional: UDP instead of multicast
  # unicast: True

  # optional: Time in seconds between hawk service is available in the first
  # node and join command is executed (20s by default)
  # wait_for_initialization: 20

  # optional: Timeout in seconds to join to the cluster
  # join_timeout: 60

  # optional: Configure a virtual IP resource in cluster
  # admin_ip: 10.20.30.40

  # optional: Configure SBD
  # sbd:
  #   # optional: Configure an SBD device
  #   device: /dev/by-label/sbd-disk
  #   # multiple disks can be set using a list
  #   device:
  #      - /dev/by-label/sbd-disk1
  #      - /dev/by-label/sbd-disk2

  # optional: Install required packages to run the cluster (true by default)
  # pre-configured packages sometimes exist for development purposes
  # install_packages: true

  # optional: ntp server
  # ntp: pool.ntp.org

  # optional: enables monitoring via the Prometheus exporter
  monitoring_enabled: true

  # optional: corosync configuration. If the entry is not set the values set by crmsh will be used
  # To configure the values, just create a dictionary with the values that have to be changed
  # If the values exists, it will be changed, otherwise it will be added.
  # Warning. The code doesn't check if the values make sense, it will put them in the configuration file
  # Here an examples
  corosync:
    totem:
      token: 30000
      interface:
        bindnetaddr: 192.168.100.1
    quorum:
      expected_votes: 3

  # optional: update hacluster password
  # hacluster_password: mypassword

  # optional: Manage ssh keys usage
  # If this entry is not set, the formula expects that the sshkeys exist and are authorized among the nodes
  # Use cases:
  # 1. ssh keys already exist and nodes are authorized to ssh each other. Don't set this entry
  # 2. ssh keys already exist but you want to overwrite them with random new keys, set overwrite to true
  # 3. ssh keys don't exist and you have the 1st node password. Use this example
  # 4. If ssh keys don't exist and you don't want to set the password here, the cluster cannot be created!
  # ssheys:
  #   # Overwrite current keys (new keys are created if no keys are found)
  #   overwrite: true # false by default
  #   # First node root password. This entry is used to configure the authorized_keys file from the joining nodes
  #   password: admin # not set by default

  # optional: Resource agents packages to install
  # resource_agents:
  #   - resouce_agent_pkg

  # optional: Configure cluster resource agents and constraints
  # configure:
  #   method: update
  #   # optional, url or template, one of them must be used
  #   url: path_to_configfile
  #   is_xml: False
  #   # optional, jinja2 template can be used to create the configuration file.
  #   template:
  #     source: path_to_template
  #     # optional
  #     destination: path_to_destination_file
  #     # optional: parameters to add in the template
  #     # the template must start with to use them: {% set data = pillar.cluster.configure.template.parameters %}
  #     parameters:
  #       param1: value1
  #       param2: value2


# -*- mode: yaml -*-
# vim: ft=yaml
